"""
AI-Powered Prompts System
Real Llama 3.1 8B integration for intelligent lyrics and style generation
"""
import os
import time
import logging
import asyncio
from typing import Dict, List, Optional
import ollama
import json
import hashlib
from datetime import datetime, timedelta

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class AIPromptsEngine:
    """Advanced AI prompts generation using Llama 3.1 8B"""
    
    def __init__(self, model_name: str = "llama3.1:8b"):
        self.model_name = model_name
        self.client = ollama.Client()
        self.prompt_cache = {}  # In-memory cache for successful prompts
        self.cache_expiry = timedelta(hours=24)
        
        # Verify model availability
        self._ensure_model_ready()
        
    def _ensure_model_ready(self) -> bool:
        """Ensure the AI model is available and ready"""
        try:
            # Check if model is available
            models = self.client.list()
            available_models = [model['name'] for model in models['models']]
            
            if self.model_name not in available_models:
                logger.warning(f"âš ï¸ Model {self.model_name} not found. Available: {available_models}")
                return False
            
            logger.info(f"âœ… AI Model {self.model_name} is ready")
            return True
            
        except Exception as e:
            logger.error(f"âŒ Error checking AI model: {e}")
            return False
    
    def _get_cache_key(self, text: str, prompt_type: str) -> str:
        """Generate cache key for prompt"""
        combined = f"{prompt_type}:{text.lower().strip()}"
        return hashlib.md5(combined.encode()).hexdigest()
    
    def _get_cached_prompt(self, cache_key: str) -> Optional[str]:
        """Get cached prompt if still valid"""
        if cache_key in self.prompt_cache:
            cached_item = self.prompt_cache[cache_key]
            if datetime.now() - cached_item['timestamp'] < self.cache_expiry:
                logger.info(f"ðŸ“‹ Using cached prompt for key: {cache_key[:8]}...")
                return cached_item['result']
            else:
                # Remove expired cache
                del self.prompt_cache[cache_key]
        return None
    
    def _cache_prompt(self, cache_key: str, result: str):
        """Cache successful prompt result"""
        self.prompt_cache[cache_key] = {
            'result': result,
            'timestamp': datetime.now()
        }
        logger.info(f"ðŸ’¾ Cached prompt result for key: {cache_key[:8]}...")
    
    def generate_lyrics(self, prompt: str, style: str = "", language: str = "spanish") -> Dict:
        """
        Generate creative lyrics based on prompt and style
        
        Args:
            prompt: Main theme/concept for the song
            style: Musical style (pop, rock, ballad, etc.)
            language: Target language for lyrics
            
        Returns:
            Dictionary with generated lyrics and metadata
        """
        try:
            logger.info(f"ðŸŽ¤ Generating lyrics for: {prompt[:30]}...")
            
            # Check cache first
            cache_key = self._get_cache_key(f"{prompt}:{style}", "lyrics")
            cached_result = self._get_cached_prompt(cache_key)
            if cached_result:
                return {"lyrics": cached_result, "cached": True, "success": True}
            
            # Construct detailed prompt for AI
            system_prompt = f"""Eres un compositor profesional especializado en {language}. 
            Tu tarea es crear letras de canciones emotivas y creativas.
            
            INSTRUCCIONES:
            - Crea letras originales y emotivas
            - Incluye estructura clara: [Verso 1], [Coro], [Verso 2], [Coro], [Puente], [Coro Final]
            - Usa lenguaje poÃ©tico pero comprensible
            - MantÃ©n coherencia narrativa
            - Adapta el tono al estilo musical solicitado
            - Longitud: 150-200 palabras aproximadamente
            
            TEMA: {prompt}
            ESTILO MUSICAL: {style if style else 'universal'}
            IDIOMA: {language}
            
            Responde SOLO con las letras, sin explicaciones adicionales."""
            
            # Generate lyrics
            response = self.client.generate(
                model=self.model_name,
                prompt=system_prompt,
                options={
                    'temperature': 0.8,  # Creative but controlled
                    'top_p': 0.9,
                    'max_tokens': 400,
                    'stop': ['[FIN]', '[END]']
                }
            )
            
            generated_lyrics = response['response'].strip()
            
            # Post-process lyrics
            processed_lyrics = self._post_process_lyrics(generated_lyrics)
            
            # Cache successful result
            self._cache_prompt(cache_key, processed_lyrics)
            
            logger.info(f"âœ… Generated lyrics: {len(processed_lyrics)} characters")
            
            return {
                "lyrics": processed_lyrics,
                "word_count": len(processed_lyrics.split()),
                "char_count": len(processed_lyrics),
                "cached": False,
                "success": True,
                "style": style,
                "language": language
            }
            
        except Exception as e:
            logger.error(f"âŒ Error generating lyrics: {e}")
            return {
                "lyrics": self._get_fallback_lyrics(prompt, style),
                "success": False,
                "error": str(e),
                "fallback": True
            }
    
    def generate_style_prompt(self, basic_input: str, mood: str = "", instruments: List[str] = None) -> Dict:
        """
        Generate creative musical style prompt from basic input
        
        Args:
            basic_input: Basic description or keywords
            mood: Desired mood/emotion
            instruments: Preferred instruments
            
        Returns:
            Dictionary with enhanced musical prompt
        """
        try:
            logger.info(f"ðŸŽµ Generating style prompt for: {basic_input[:30]}...")
            
            # Check cache
            cache_key = self._get_cache_key(f"{basic_input}:{mood}:{instruments}", "style")
            cached_result = self._get_cached_prompt(cache_key)
            if cached_result:
                return {"prompt": cached_result, "cached": True, "success": True}
            
            instruments_text = ", ".join(instruments) if instruments else "instrumentos variados"
            
            system_prompt = f"""Eres un productor musical experto en crear prompts detallados para generaciÃ³n de mÃºsica.
            Tu tarea es transformar ideas bÃ¡sicas en prompts musicales ricos y especÃ­ficos.
            
            INSTRUCCIONES:
            - Convierte la idea bÃ¡sica en un prompt musical detallado
            - Incluye informaciÃ³n sobre: gÃ©nero, tempo, instrumentaciÃ³n, atmÃ³sfera
            - Agrega detalles tÃ©cnicos especÃ­ficos cuando sea relevante
            - MantÃ©n el prompt entre 50-100 palabras
            - Usa lenguaje tÃ©cnico musical profesional
            - Hazlo especÃ­fico y evocativo
            
            IDEA BÃSICA: {basic_input}
            MOOD DESEADO: {mood if mood else 'versÃ¡til'}
            INSTRUMENTOS PREFERIDOS: {instruments_text}
            
            Responde SOLO con el prompt musical mejorado, sin explicaciones."""
            
            response = self.client.generate(
                model=self.model_name,
                prompt=system_prompt,
                options={
                    'temperature': 0.7,
                    'top_p': 0.8,
                    'max_tokens': 200
                }
            )
            
            enhanced_prompt = response['response'].strip()
            
            # Post-process prompt
            processed_prompt = self._post_process_style_prompt(enhanced_prompt)
            
            # Cache result
            self._cache_prompt(cache_key, processed_prompt)
            
            logger.info(f"âœ… Generated style prompt: {len(processed_prompt)} characters")
            
            return {
                "prompt": processed_prompt,
                "original_input": basic_input,
                "mood": mood,
                "instruments": instruments,
                "cached": False,
                "success": True
            }
            
        except Exception as e:
            logger.error(f"âŒ Error generating style prompt: {e}")
            return {
                "prompt": self._get_fallback_style_prompt(basic_input, mood),
                "success": False,
                "error": str(e),
                "fallback": True
            }
    
    def improve_existing_lyrics(self, lyrics: str, improvement_type: str = "general") -> Dict:
        """
        Improve existing lyrics with AI suggestions
        
        Args:
            lyrics: Original lyrics to improve
            improvement_type: Type of improvement (rhyme, flow, emotion, etc.)
            
        Returns:
            Dictionary with improved lyrics
        """
        try:
            logger.info(f"âœ¨ Improving lyrics: {improvement_type}")
            
            improvement_instructions = {
                "rhyme": "Mejora la rima y mÃ©trica de estas letras",
                "emotion": "Aumenta la carga emocional y expresividad",
                "flow": "Mejora el flujo y ritmo para cantabilidad",
                "structure": "Reorganiza la estructura para mayor impacto",
                "general": "Mejora estas letras manteniendo su esencia"
            }
            
            instruction = improvement_instructions.get(improvement_type, improvement_instructions["general"])
            
            system_prompt = f"""{instruction}:

LETRAS ORIGINALES:
{lyrics}

INSTRUCCIONES:
- MantÃ©n el mensaje y tema original
- Mejora segÃºn el tipo solicitado: {improvement_type}
- Conserva la estructura existente cuando sea posible
- Haz cambios sutiles pero efectivos
- Responde SOLO con las letras mejoradas

LETRAS MEJORADAS:"""
            
            response = self.client.generate(
                model=self.model_name,
                prompt=system_prompt,
                options={
                    'temperature': 0.6,
                    'top_p': 0.8,
                    'max_tokens': 500
                }
            )
            
            improved_lyrics = response['response'].strip()
            processed_lyrics = self._post_process_lyrics(improved_lyrics)
            
            logger.info(f"âœ… Improved lyrics: {improvement_type}")
            
            return {
                "improved_lyrics": processed_lyrics,
                "original_lyrics": lyrics,
                "improvement_type": improvement_type,
                "success": True
            }
            
        except Exception as e:
            logger.error(f"âŒ Error improving lyrics: {e}")
            return {
                "improved_lyrics": lyrics,  # Return original on error
                "success": False,
                "error": str(e)
            }
    
    def analyze_music_prompt(self, prompt: str) -> Dict:
        """
        Analyze a music prompt and provide suggestions
        
        Args:
            prompt: Music prompt to analyze
            
        Returns:
            Dictionary with analysis and suggestions
        """
        try:
            logger.info(f"ðŸ” Analyzing music prompt...")
            
            system_prompt = f"""Analiza este prompt musical y proporciona sugerencias de mejora:

PROMPT: {prompt}

Proporciona un anÃ¡lisis en formato JSON con:
- "genre": gÃ©nero musical detectado
- "mood": estado de Ã¡nimo/emociÃ³n
- "tempo": tempo sugerido (lento/medio/rÃ¡pido)
- "instruments": instrumentos sugeridos
- "suggestions": lista de mejoras especÃ­ficas
- "clarity_score": puntuaciÃ³n de claridad (1-10)

Responde SOLO con el JSON vÃ¡lido."""
            
            response = self.client.generate(
                model=self.model_name,
                prompt=system_prompt,
                options={
                    'temperature': 0.3,
                    'top_p': 0.7,
                    'max_tokens': 300
                }
            )
            
            try:
                analysis = json.loads(response['response'].strip())
            except json.JSONDecodeError:
                # Fallback parsing
                analysis = self._parse_analysis_fallback(response['response'])
            
            logger.info(f"âœ… Analyzed prompt successfully")
            
            return {
                "analysis": analysis,
                "original_prompt": prompt,
                "success": True
            }
            
        except Exception as e:
            logger.error(f"âŒ Error analyzing prompt: {e}")
            return {
                "analysis": self._get_fallback_analysis(prompt),
                "success": False,
                "error": str(e)
            }
    
    def _post_process_lyrics(self, lyrics: str) -> str:
        """Post-process generated lyrics for consistency"""
        # Clean up formatting
        lines = lyrics.split('\n')
        processed_lines = []
        
        for line in lines:
            line = line.strip()
            if line:
                # Ensure proper capitalization
                if line and line[0].islower() and not line.startswith('['):
                    line = line[0].upper() + line[1:]
                
                # Ensure structure markers are properly formatted
                if any(marker in line.lower() for marker in ['verso', 'coro', 'puente', 'estribillo']):
                    if not line.startswith('[') or not line.endswith(']'):
                        line = f"[{line.strip('[]')}]"
                
                processed_lines.append(line)
            else:
                processed_lines.append('')
        
        return '\n'.join(processed_lines)
    
    def _post_process_style_prompt(self, prompt: str) -> str:
        """Post-process style prompt for consistency"""
        # Clean and enhance the prompt
        prompt = prompt.strip()
        
        # Ensure it doesn't end with punctuation that might confuse AI
        if prompt.endswith('.'):
            prompt = prompt[:-1]
        
        # Ensure it's descriptive enough
        if len(prompt) < 30:
            prompt += ", con producciÃ³n profesional y sonido pulido"
        
        return prompt
    
    def _get_fallback_lyrics(self, prompt: str, style: str) -> str:
        """Generate fallback lyrics when AI fails"""
        fallback_templates = {
            "pop": f"""[Verso 1]
{prompt} me inspira cada dÃ­a
Como una melodÃ­a que no se olvida
En cada nota encuentro la alegrÃ­a
De una historia que apenas comienza

[Coro]
Esta es nuestra canciÃ³n
Que nace del corazÃ³n
Con {prompt}
Bailamos sin cesar

[Verso 2]
Las palabras fluyen como el viento
Llevando mensajes de esperanza
En cada verso un sentimiento
Que nos une en esta danza""",
            
            "rock": f"""[Verso 1]
{prompt} enciende el fuego interior
Como guitarras que gritan verdad
En cada acorde hay un rugido
Que despierta nuestra libertad

[Coro]
Romperemos las cadenas
Con el poder del rock
{prompt} en nuestras venas
Nada nos va a parar

[Verso 2]
Los amplificadores devoran el silencio
Y en cada golpe de baterÃ­a
Nace la fuerza de nuestro grito
Que resuena hasta el nuevo dÃ­a""",
            
            "ballad": f"""[Verso 1]
En la quietud de la noche
{prompt} me acompaÃ±a
Como susurros del alma
Que calman cuando el corazÃ³n se daÃ±a

[Coro]
Esta balada es para ti
Escrita en las estrellas
Con {prompt}
Te canto estas querelas

[Verso 2]
Las lÃ¡grimas se vuelven melodÃ­a
Y el dolor se transforma en canciÃ³n
En cada nota hay poesÃ­a
Que sana cada herida del corazÃ³n"""
        }
        
        return fallback_templates.get(style.lower(), fallback_templates["pop"])
    
    def _get_fallback_style_prompt(self, basic_input: str, mood: str) -> str:
        """Generate fallback style prompt"""
        mood_descriptors = {
            "happy": "alegre y energÃ©tico",
            "sad": "melancÃ³lico y emotivo", 
            "energetic": "vibrante y dinÃ¡mico",
            "peaceful": "sereno y contemplativo",
            "romantic": "romÃ¡ntico y suave"
        }
        
        mood_desc = mood_descriptors.get(mood.lower(), "expresivo")
        
        return f"Una composiciÃ³n {mood_desc} inspirada en {basic_input}, con instrumentaciÃ³n rica y producciÃ³n moderna, tempo medio, ideal para transmitir emociones profundas"
    
    def _parse_analysis_fallback(self, response_text: str) -> Dict:
        """Parse analysis response when JSON fails"""
        return {
            "genre": "universal",
            "mood": "expresivo",
            "tempo": "medio", 
            "instruments": ["piano", "guitarra", "baterÃ­a"],
            "suggestions": ["Agregar mÃ¡s detalles especÃ­ficos", "Definir mejor el gÃ©nero"],
            "clarity_score": 7
        }
    
    def _get_fallback_analysis(self, prompt: str) -> Dict:
        """Generate fallback analysis"""
        return {
            "genre": "pop",
            "mood": "neutral",
            "tempo": "medio",
            "instruments": ["varios"],
            "suggestions": ["El prompt estÃ¡ bien estructurado"],
            "clarity_score": 8
        }
    
    def get_cache_stats(self) -> Dict:
        """Get cache statistics"""
        return {
            "cached_prompts": len(self.prompt_cache),
            "cache_size_mb": sum(len(str(item)) for item in self.prompt_cache.values()) / (1024 * 1024),
            "oldest_cache": min([item['timestamp'] for item in self.prompt_cache.values()]) if self.prompt_cache else None
        }
    
    def clear_cache(self):
        """Clear prompt cache"""
        self.prompt_cache.clear()
        logger.info("ðŸ§¹ Prompt cache cleared")


# Global instance
ai_engine = AIPromptsEngine()